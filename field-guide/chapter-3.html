 <!DOCTYPE html>
 <html lang="en">
   <head>
     <meta charset="utf-8" />
     <meta name="description" content="Essential subjects for survival, evasion, maintenance, and combatives." />
	<link rel="stylesheet" href="styles/chapter-3.css" />
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto" />
   	<link rel="stylesheet" href="styles/main.css" />
   	
     <title>Chapter 3 | Tesladyne Industries :: Field Guide</title>
   </head>

   <body>
    <main>
      <header>
        <img src="images/chapter-3.png" alt="Chapter 3" />

        <h1>Chapter 3</h1>
        
        <p>TITLE IS LONG</p>

        <h2>So, Someone Plugged An Automatic Intelligence Into The Military Industrial Complex And Now There Are Robot Factories Pumping Out Hunter-killer Drones</h2>
      </header>

      <section>
        <p>As of this printing it hasn&rsquo;t happened yet, but it&rsquo;s only a matter of time.</p>

        <p>On the other hand, as far as we know, this book is one of the few remaining artifacts of The World That Was before the robot uprising. Perhaps you worship it as a religious document. Hopefully your peoples have retained basic literacy so the message hasn&rsquo;t become corrupted over time. It is also our hope that your leaders don&rsquo;t apply disingenuous interpretations of our text to justify the consolidation of their wealth and power via a permanent, if ever-changing, underclass.</p>

        <p>If this is the case, we regret to inform you that peasant uprisings are outside the scope of this work, but we of the mythic Golden Age of Mankind wish you the best of luck.</p>

        <p>Meanwhile, robots!</p>

        <p>We&rsquo;ll start with the bad news. There is no way to win an all out global conflict against robotic hordes.</p>

        <p>But here&rsquo;s the good news! It probably won&rsquo;t come to an all out war because we are optimally equipped to shut down wide scale human/robot conflict before it ever begins! Our vigilance is the best defense.</p>

        <h3>True AI won&rsquo;t want to kill us. Probably.</h3>

        <p>In nature, we find greater emotional complexity tied to greater intellectual complexity.</p>

        <p>Mammals are both the most emotionally complicated creatures and the most intelligent.</p>

        <p>The link may not be casual: emotional capacity doesn&rsquo;t <em>create</em> intellectual capacity. But neural architecture complex enough to give rise to one seems to be a fertile ground for the other as well. One school of thought proposes that an AI at least as smart as a human won&rsquo;t be a cold, logical killing machine that sees no choice but to remove our inefficient meat bodies from the equations of the Earth. On the contrary, it would likely be, well, nice. Possibly to the extent of being horrified by the idea of <em>not</em> being nice. You&rsquo;d have to go <em>well</em> out of your way to turn that sort of AI into a genocidal maniac.</p>

        <p>Solution: don&rsquo;t.</p>

        <h3>Even if the AIs wanted to kill us, we own all the factories.</h3>

        <p>Simply put: we are going to notice if portions of our industrial sectors stop making cell phones and cards and start making threshers covered in howitzers with computer brains where the driver ought to sit.</p>

        <p>And even getting to <em>that</em> point is a stretch, because the AI would have to completely alter the infrastructure and talent pool of these places just to <em>start</em> converting them into death factories.</p>

        <p>Solution: keep an eye on the means of production.</p>

        <h3>What about those autonomous military drones we&rsquo;re racing to build?</h3>

        <p>Okay, yeah, bad idea. Making these things doesn&rsquo;t merely strip us of our main defense against robot domination as described by #2 above, it gives them the primary tool with which they can murder us all.</p>

        <p>This is like getting mugged and handing the mugger a better gun. Only the mugger hasn&rsquo;t been born yet and you&rsquo;re spending billions of dollars to make sure that when he is, he&rsquo;ll feel like he has no stake in society, so his best chance for survival is committing crimes that specifically target you.</p>

        <p>That&rsquo;s a big pile of needlessly destructive ideas.</p>

        <p>Solution: stop trying to make those. Or, if you insist, at least make them remote controlled so they can&rsquo;t make their own choices.</p>

        <h3>We didn&rsquo;t read this book in time, we <em>didn&rsquo;t</em> do those things we should have, <em>and</em> did all those things we weren&rsquo;t supposed to. Now there&rsquo;s an active, growing, and coordinated force of robots hellbent on the eradication of all organic life. WHAT NOW???</h3>

        <p><strong>DO</strong> form a resistance.</p>

        <p><strong>DON&rsquo;T</strong> try to travel back in time. It will end in tears and you&rsquo;re better off using those resources to fight the war in front of you. Unless the robots invent a time machine first, in which case it would be a sound strategy to hijack that thing. Results of using it likely range from futile to catastrophic. Best of luck.</p>

        <p><strong>DO</strong> reference <a href="chapter-1.html">CHAPTER 1: WHEN DINOSAURS ATTACK</a>. You will find much of it applies to robots too.</p>

        <p><strong>DON&rsquo;T</strong> try to ride the robots though.</p>

        <p><strong>DO</strong> a lot of sabotage. It is folly to engage the robots in conventional warfare. You can think of them as tanks and yourself as a balloon filled with blood. While it&rsquo;s true that throwing enough blood balloons against a tank might just slow it down for a bit, being sneaky smart about where you put explosive charges would work out much better for you.</p>

        <p>Your should expect to encounter cloud-intelligence hiveminds. These are networks wherein each member can act independently while contributing a portion of its processing power to overall intelligence. A big enough network, then, is smarter than anything in it. scary stuff!</p>

        <p>We can&rsquo;t address the specifics of such systems, such as if you should hack it and if so, how. As far as the authors of this paper know, these networks routinely employ morphological architecture that alters itself to immunize against incoming code-based attacks.</p>

        <p>Hiveminds grow in power as the number of individual nodes grow, but paradoxically they become more vulnerable too. Each node is a target for attack. And your primary attack should be misinformation.</p>

        <p>If you impair or even destroy a sinlge node, you&rsquo;ve done little damage to the hivemind and likely <strong>no</strong> damage whatever to any other nodes. Misinformation, however, can spread across the entire network and poison all future decisions it makes. Even if the hivemind can positively identify misinformation, that alone can cause delays and doubts to ripple throughout its network as it must now devote computational resources to constantly guard against new misinformation and to double-check previously held beliefs.</p>

        <p>This can be exploited in all kinds of ways. Get creative and you could get the hivemind to argue with itself as more of its nodes contribute contradictory misinformation.</p>

        <h4>ANALOG WORLD VS DIGITAL WARRIOR</h4>

        <p>Our most powerful tool against the robots is the natural world. This fact is overlooked almost entirely in human/robot war literature because humans are the ones writing it, and humans tend to think of the natural world as basically a good thing to be in. Sure, we like out air conditioning, to be sheltered from the rain, and to avoid poisonous snakes, but in general we view the habitable zone of the Earth to be a pretty great thing to be in. This is no coincidence! Trillions of experiments conducted over billions of years have produced a staggering array of creatures about as optimally adapted to the myriad environmental niches of the Earth as you can imagine. And we&rsquo;re one of them!</p>

        <p>Robots, on the other hand, were developed in laboratories, in warehouses and garages. The natural world is alien to them and they do not belong in it. Of course, the natural world is full of danger to man as well machine, but there&rsquo;s an enormous difference between being killed by a bear and your brain frying itself to death because it&rsquo;s a little humid out.</p>

        <p>Consider all the work it takes for a human to survive in space for a few weeks. All the systems that have to be created, tested, and maintained, all fail safes (and fail safes <em>for</em> the fail safes) for those systems in case something foes wrong. <em>That&rsquo;s</em> the kind of over-engineering the robots will have to front load into <em>all</em> of their designs if they expect to go outside to get at us.</p>

        <p>Just as we have to bottle up parts of our biosphere into a containment suit to survive in space, the robot body is <em>its</em> containment suit. We evolved in a messy and dirty Earth. Robots evolved in a sterile and controlled laboratory. And just as a small hole in a spacesuit can cause a human a great deal of distress, even minimal damage to a robot&rsquo;s outer layers can wreak havoc on its ability to function.</p>

        <p>Look at it like this. You get dirt in your mouth, it&rsquo;s kind of gross and you get on with your life. But get some dirt in a robot&rsquo;s intake and there&rsquo;s a good chance it&rsquo;ll overheat, or shutdown to avoid damaging precisely aligned moving parts.</p>

        <p>The dirtier, muckier, and wetter the environment, the better your odds. Don&rsquo;t fight these guys in the barren and blasted out ruins of a city if you can help it. Get them into forests and swamps!</p>
      </section>

      <footer>
        <img src="images/logo-tesladyne.png" alt="Logo Tesladyne Industries" />

        <p>
          <small>All images and content taken from Atomic Robo.</small>
          <br />
          <small>Atomic Robo is Copyright Brian Clevinger and Scott Wegener.</small>
        </p>
      </footer>
    </main>

    <nav>
      <ul>
        <li>
          <a href="index.html">Home</a>
        </li>

        <li>
          <a href="chapter-1.html">
            Chapter 1
            <span>When Dinosaurs Attack</span>
          </a>
        </li>

        <li>
          <a href="chapter-2.html">
            Chapter 2
            <span>Lasers Do Not Go Pew Pew</span>
          </a>
        </li>

        <li>
          <a class="current" href="chapter-3.html">
            Chapter 3
            <span>So, Someone Plugged An Automatic Intelligence Into The Military Industrial Complex And Now There Are Robot Factories Pumping Out Hunter-killer Drones</span>
          </a>
        </li>

        <li>
          <a href="chapter-4.html">
            Chapter 4
            <span>Are You Living Inside A Simulation?</span>
          </a>
        </li>

        <li>
          <a href="chapter-5.html">
            Chapter 5
            <span>Huge Explosions: The Deadly Killer</span>
          </a>
        </li>

        <li>
          <a href="chapter-6.html">
            Chapter 6
            <span>So You&rsquo;ve Got An Evil Twin</span>
          </a>
        </li>

        <li>
          <a href="chapter-7.html">
            Chapter 7
            <span>Exotic Geometries And You</span>
          </a>
        </li>

        <li>
          <a href="chapter-8.html">
            Chapter 8
            <span>Lightning Gun Maintenance</span>
          </a>
        </li>

        <li>
          <a href="chapter-9.html">
            Chapter 9
            <span>Doctor Dinosaur Gets His Own Chapter</span>
          </a>
        </li>

        <li>
          <a href="chapter-10.html">
            Chapter 10
            <span>Dimensional Science: Do Not Fiddle With The Knobs</span>
          </a>
        </li>

        <li>
          <a href="chapter-11.html">
            Chapter 11
            <span>Time Travel: No, No, No, No, No</span>
          </a>
        </li>
      </ul>
    </nav>
   </body>
 </html>
